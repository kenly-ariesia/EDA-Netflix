# -*- coding: utf-8 -*-
"""EDA Exercise

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M5PxdZb6rkdR35ZsDBG-LKaDR6QWrthh

# Dataset Identification
"""

import pandas as pd

df = pd.read_csv('/content/Netflix Data.csv')

print (df)

"""Some values in the 'Director' column have a 'Not Given' value, which can be assumed to be empty or missing.

# Handling Missing Value
"""

# Checking dataset missing information
df.info()

"""We can't see numerically that the data is empty because it is filled by the value 'Not Given'"""

# Calculate the percentage of 'Not Given' values in the 'director' column
column_total = len(df)
not_given_total = (df['director'] == 'Not Given').sum()
percentage = (not_given_total / column_total) * 100

print(f"'Not Given' Total:{not_given_total}")
print(f"'Not Given' Percentage: {percentage:.2f}%")

"""The percentage value of 'Not Given' is considered too large and will disrupt the dataset results if all values with the 'director' column 'Not Given' are removed

The 'Not Given' data will be replaced with another label to ensure the dataset does not shift significantly
"""

import numpy as np

# Changing 'Not Given' data to np.nan so it can be recognized as a missing value
df['director'] = df['director'].replace('Not Given', np.nan)

# Calculating total and missing value percentage
missing_total = df['director'].isna().sum()
missing_percentage = (missing_total / column_total) * 100

print(f"Missing Total in 'director' column: {missing_total}")
print(f"Missing Value Percentage: {missing_percentage:.2f}%")

# Re-calculate to make sure 'Not Given' data has changed to missing value
column_total = len(df)
not_given_total = (df['director'] == 'Not Given').sum()
percentage = (not_given_total / column_total) * 100

print(f"'Not Given' Total:{not_given_total}")
print(f"'Not Given' Percentage: {percentage:.2f}%")

# Using mode to replace 'missing value' data
modus_director = df['director'].mode()[0]
df['director'].fillna(modus_director,inplace=True)

# Final result
print("\nClean Data")
print(df)

"""The data in the 'director' column now no longer contains 'Not Given'

# Resolve Duplicate Data
"""

# Checking duplicate data in all column
check_duplicate_all = df.duplicated().sum()
print(f"Duplicate Total = {check_duplicate_all}")

"""No duplicate data in all columns"""

# Checking duplicate data in each column
duplicate_rows = df[df.duplicated(
    subset=['title', 'director', 'country', 'date_added','release_year', 'rating', 'duration', 'listed_in'],
    keep=False)]
print(duplicate_rows)

"""Visible duplicate data detected. In the previous calculation, duplicate data was not detected possibly because of the ID in the data."""

# Cleaning duplicate
df_clean = df.drop_duplicates(subset=['title', 'director', 'country', 'date_added',
       'release_year', 'rating', 'duration', 'listed_in'], keep='first',inplace=True)

# Re-check duplicate data
duplicate_check = df[df.duplicated(subset=['title', 'director', 'country', 'date_added',
                                           'release_year', 'rating', 'duration', 'listed_in'],keep=False)]

print(duplicate_check)

"""Data successfully cleaned from duplicate and missing value"""